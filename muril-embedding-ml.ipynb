{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11001207,"sourceType":"datasetVersion","datasetId":6848383}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom transformers import BertModel, BertTokenizer\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.optim as optim\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:13:52.852880Z","iopub.execute_input":"2025-03-22T06:13:52.853295Z","iopub.status.idle":"2025-03-22T06:14:18.942786Z","shell.execute_reply.started":"2025-03-22T06:13:52.853257Z","shell.execute_reply":"2025-03-22T06:14:18.941863Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import re\nimport emoji\nimport pandas as pd\n\n# Load data\ntrain_df = pd.read_csv(\"/kaggle/input/caste-and-migration-hate-speech-detection/train.csv\")\ndev_df = pd.read_csv(\"/kaggle/input/caste-and-migration-hate-speech-detection/dev.csv\")\ndf = pd.concat([train_df, dev_df], ignore_index=True)\n\n# Function to clean each text\ndef preprocess_text(text):\n    # Replace mentions\n    text = re.sub(r'@\\w+', '<USER>', text)\n    \n    # Replace hashtags\n    text = re.sub(r'#\\w+', '<HASHTAG>', text)\n    \n    # Convert emojis to text (e.g., ЁЯШК -> :smiling_face_with_smiling_eyes:)\n    text = emoji.demojize(text, delimiters=(\" \", \" \"))  # adds spaces around emoji descriptions\n    \n    # Optional: Remove extra whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\n# Apply preprocessing to your column (assuming it's called 'text')\ndf['text'] = df['text'].apply(preprocess_text)\ndf.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:14:18.943933Z","iopub.execute_input":"2025-03-22T06:14:18.944607Z","iopub.status.idle":"2025-03-22T06:14:19.884290Z","shell.execute_reply.started":"2025-03-22T06:14:18.944577Z","shell.execute_reply":"2025-03-22T06:14:19.883199Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        id                                               text  label\n4272  4843  роЗроирпНродро┐роХро╛ро░ро░рпНроХро│рпН родрооро┐ро┤ро░рпНроХро│рпИ роЕроЯро┐родрпНродрпБ ро╡ро┐ро░роЯрпНроЯро┐ роЗродрпБ роЗрои...      1\n4616  4700  100 rubai kooda sambarika mudilanu thaan varan...      0\n4414  2720  Ena da tharkuri thailees mari video podringa n...      1\n613   6438  роЗроирпНрод ро╡рпЗро│ро╛ро│ро░рпН роХрпБроЯро┐ропро┐ройро░рпН роПройрпН рокро│рпНро│ро░рпНроХро│рпБроХрпНроХрпБ ро╡рпЗро│ро╛ро│...      0\n5029  1925                  ро╡рпАроЯрпБ родроирпНродро╡ройрпИ роЪрпЖро░рпБрокрпНрокро╛ро▓ роЕроЯро┐роХрпНроХройрпБроорпН      0\n3186  3358  родрооро┐ро┤рпНроиро╛роЯрпНроЯро┐ро▓рпН рокроЯро┐роХрпНроХро╛рооро▓рпН ро╡рпЗро▓рпИ роЗро▓рпНро▓ро╛рооро▓рпН роиро┐ро▒рпИроп рок...      0\n3058   933             родро┐роЯрпНроЯроорпН рокрпЛроЯрпНроЯрпБ роиро╛роЯрпНроЯрпИ рокро┐роЯро┐роХрпНроХро┐ро▒ро╛ройрпН....      0\n130   1498  роиро╛роорпН родрооро┐ро┤ро░рпН роХроЯрпНроЪро┐ропрпИ роОроирпНрод роХрпКроорпНрокройро╛ро▓рпБроорпН роТройрпНро▒рпБроорпН роЪ...      0\n3666   397  роиро╛ройрпН роОройрпНройрпБроЯрпИроп рокроЯрпНроЯро▒рпИропро┐ро▓рпН родрооро┐ро┤рпН роЖроЯрпНроХро│рпН родро╛ройрпН ро╡рпИрод...      0\n1280  3470  роТро░рпБроиро╛ро│рпН роироорпНроорпИ роЕройрпИродрпНродро┐ро▓рпБроорпН роЕро┤ро┐рокрпНрокро╛ро░рпНроХро│рпН, роЕродро▒рпНроХрпБ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4272</th>\n      <td>4843</td>\n      <td>роЗроирпНродро┐роХро╛ро░ро░рпНроХро│рпН родрооро┐ро┤ро░рпНроХро│рпИ роЕроЯро┐родрпНродрпБ ро╡ро┐ро░роЯрпНроЯро┐ роЗродрпБ роЗрои...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4616</th>\n      <td>4700</td>\n      <td>100 rubai kooda sambarika mudilanu thaan varan...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4414</th>\n      <td>2720</td>\n      <td>Ena da tharkuri thailees mari video podringa n...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>6438</td>\n      <td>роЗроирпНрод ро╡рпЗро│ро╛ро│ро░рпН роХрпБроЯро┐ропро┐ройро░рпН роПройрпН рокро│рпНро│ро░рпНроХро│рпБроХрпНроХрпБ ро╡рпЗро│ро╛ро│...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5029</th>\n      <td>1925</td>\n      <td>ро╡рпАроЯрпБ родроирпНродро╡ройрпИ роЪрпЖро░рпБрокрпНрокро╛ро▓ роЕроЯро┐роХрпНроХройрпБроорпН</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3186</th>\n      <td>3358</td>\n      <td>родрооро┐ро┤рпНроиро╛роЯрпНроЯро┐ро▓рпН рокроЯро┐роХрпНроХро╛рооро▓рпН ро╡рпЗро▓рпИ роЗро▓рпНро▓ро╛рооро▓рпН роиро┐ро▒рпИроп рок...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3058</th>\n      <td>933</td>\n      <td>родро┐роЯрпНроЯроорпН рокрпЛроЯрпНроЯрпБ роиро╛роЯрпНроЯрпИ рокро┐роЯро┐роХрпНроХро┐ро▒ро╛ройрпН....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>1498</td>\n      <td>роиро╛роорпН родрооро┐ро┤ро░рпН роХроЯрпНроЪро┐ропрпИ роОроирпНрод роХрпКроорпНрокройро╛ро▓рпБроорпН роТройрпНро▒рпБроорпН роЪ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3666</th>\n      <td>397</td>\n      <td>роиро╛ройрпН роОройрпНройрпБроЯрпИроп рокроЯрпНроЯро▒рпИропро┐ро▓рпН родрооро┐ро┤рпН роЖроЯрпНроХро│рпН родро╛ройрпН ро╡рпИрод...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1280</th>\n      <td>3470</td>\n      <td>роТро░рпБроиро╛ро│рпН роироорпНроорпИ роЕройрпИродрпНродро┐ро▓рпБроорпН роЕро┤ро┐рокрпНрокро╛ро░рпНроХро│рпН, роЕродро▒рпНроХрпБ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"texts = df['text'].tolist()\nlabels = df['label'].tolist()\nlen(texts), len(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:14:19.886271Z","iopub.execute_input":"2025-03-22T06:14:19.886657Z","iopub.status.idle":"2025-03-22T06:14:19.893206Z","shell.execute_reply.started":"2025-03-22T06:14:19.886628Z","shell.execute_reply":"2025-03-22T06:14:19.892249Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(6299, 6299)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n\n# Load the MurIL tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained('google/muril-base-cased')\nmodel = AutoModel.from_pretrained('google/muril-base-cased')\n\n# Check if CUDA is available and move the model to the appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:14:49.840132Z","iopub.execute_input":"2025-03-22T06:14:49.840523Z","iopub.status.idle":"2025-03-22T06:14:58.413335Z","shell.execute_reply.started":"2025-03-22T06:14:49.840489Z","shell.execute_reply":"2025-03-22T06:14:58.411650Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33aa93493c84b1eb2a44d1a9d7a1d5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708169b5903842808b7674bccd5e8742"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce8b139fec624fa8b1606dc1d1d004e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50562f14d6714244bb310c878cb79b65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/953M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c026b5fc0ce451c8c8001055779bd04"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(197285, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def tokenize_texts(texts):\n    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n        self.tokenized_data = tokenize_texts(texts)\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.tokenized_data['input_ids'][idx],\n            'attention_mask': self.tokenized_data['attention_mask'][idx],\n            'label': self.labels[idx]\n        }\n\ndataset = TextDataset(texts, labels)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:15:00.558532Z","iopub.execute_input":"2025-03-22T06:15:00.558929Z","iopub.status.idle":"2025-03-22T06:15:01.424964Z","shell.execute_reply.started":"2025-03-22T06:15:00.558886Z","shell.execute_reply":"2025-03-22T06:15:01.423888Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"all_embeddings = []\n# Forward pass\nwith torch.no_grad():\n    for batch in dataloader:\n        inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n        outputs = model(**inputs)\n        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n        all_embeddings.append(cls_embeddings.cpu())\n        \nX = torch.cat(all_embeddings).numpy()\ny = np.array(labels)\n\n# Save embeddings\nnp.save(\"muril_embeddings.npy\", X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:15:10.312691Z","iopub.execute_input":"2025-03-22T06:15:10.313045Z","iopub.status.idle":"2025-03-22T06:15:51.414012Z","shell.execute_reply.started":"2025-03-22T06:15:10.313020Z","shell.execute_reply":"2025-03-22T06:15:51.412978Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:16:20.979007Z","iopub.execute_input":"2025-03-22T06:16:20.979374Z","iopub.status.idle":"2025-03-22T06:16:21.042853Z","shell.execute_reply.started":"2025-03-22T06:16:20.979328Z","shell.execute_reply":"2025-03-22T06:16:21.042063Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"models = [\n    LogisticRegression(max_iter=1000),\n    RandomForestClassifier(n_estimators=100),\n    SVC(kernel='rbf'),\n    MultinomialNB(),\n    KNeighborsClassifier(n_neighbors=5),\n    GradientBoostingClassifier(),\n    XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n    LGBMClassifier()\n]\nmodel_names = ['Logistic Regression', 'Random Forest', 'SVM', 'Naive Bayes', 'KNN', 'Gradient Boosting', 'XGBoost', 'LightGBM']\n\nresults = {}\n\nfor model, name in zip(models, model_names):\n    model.fit(X_train_scaled, y_train)\n    y_pred = model.predict(X_val_scaled)\n    \n    acc = accuracy_score(y_val, y_pred)\n    f1_macro = f1_score(y_val, y_pred, average='macro')  # <-- Macro F1\n    cm = confusion_matrix(y_val, y_pred)\n    \n    results[name] = {\n        'Model': model,\n        'Accuracy': acc,\n        'Macro F1 Score': f1_macro,\n        'Confusion Matrix': cm\n    }\n    \n    print(f\"{name} -> Accuracy: {acc:.4f}, Macro F1 Score: {f1_macro:.4f}\")\n    print(\"Confusion Matrix:\\n\", cm)\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T06:16:28.428840Z","iopub.execute_input":"2025-03-22T06:16:28.429142Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression -> Accuracy: 0.6921, Macro F1 Score: 0.6428\nConfusion Matrix:\n [[670 128]\n [260 202]]\n--------------------------------------------------\nRandom Forest -> Accuracy: 0.7738, Macro F1 Score: 0.7276\nConfusion Matrix:\n [[747  51]\n [234 228]]\n--------------------------------------------------\nSVM -> Accuracy: 0.7127, Macro F1 Score: 0.6469\nConfusion Matrix:\n [[721  77]\n [285 177]]\n--------------------------------------------------\nNaive Bayes -> Accuracy: 0.6063, Macro F1 Score: 0.5335\nConfusion Matrix:\n [[631 167]\n [329 133]]\n--------------------------------------------------\nKNN -> Accuracy: 0.6421, Macro F1 Score: 0.6108\nConfusion Matrix:\n [[583 215]\n [236 226]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"voting_clf = VotingClassifier(estimators=[\n    ('lr', models[0]), ('rf', models[1]), ('svm', models[2])], voting='hard')\nvoting_clf.fit(X_train_scaled, y_train)\ny_pred_voting = voting_clf.predict(X_val_scaled)\nacc_voting = accuracy_score(y_val, y_pred_voting)\nf1_voting = f1_score(y_val, y_pred_voting, average='macro')\ncm_voting = confusion_matrix(y_val, y_pred_voting)\n\nresults['Voting Classifier'] = {\n    'Model': voting_clf,\n    'Accuracy': acc_voting,\n    'Macro F1 Score': f1_voting,\n    'Confusion Matrix': cm_voting\n}\n\nstacking_clf = StackingClassifier(\n    estimators=[('lr', models[0]), ('rf', models[1]), ('svm', models[2])],\n    final_estimator=LogisticRegression()\n)\nstacking_clf.fit(X_train_scaled, y_train)\ny_pred_stacking = stacking_clf.predict(X_val_scaled)\nacc_stacking = accuracy_score(y_val, y_pred_stacking)\nf1_stacking = f1_score(y_val, y_pred_stacking, average='macro')\ncm_stacking = confusion_matrix(y_val, y_pred_stacking)\n\nresults['Stacking Classifier'] = {\n    'Model': stacking_clf,\n    'Accuracy': acc_stacking,\n    'Macro F1 Score': f1_stacking,\n    'Confusion Matrix': cm_stacking\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_labels = list(results.keys())\naccuracies = [results[m]['Accuracy'] for m in model_labels]\nf1_scores = [results[m]['Macro F1 Score'] for m in model_labels]\n\nfig, ax = plt.subplots(figsize=(12, 6))\nx = np.arange(len(model_labels))\nbar_width = 0.35\n\nbars1 = ax.bar(x - bar_width/2, accuracies, bar_width, label='Accuracy', color='skyblue')\nbars2 = ax.bar(x + bar_width/2, f1_scores, bar_width, label='F1 Score', color='salmon', alpha=0.8)\n\n# Annotate bars with values on top\nfor bar in bars1:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2, height + 0.01, f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n\nfor bar in bars2:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2, height + 0.01, f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n\nax.set_xlabel('Models')\nax.set_ylabel('Score')\nax.set_title('Accuracy and F1 Score of Models')\nax.set_xticks(x)\nax.set_xticklabels(model_labels, rotation=45, ha='right')\nax.legend()\nplt.tight_layout()\nplt.grid(True, linestyle='--', alpha=0.3)\nplt.show()\n\n# ==========================\n# Plot Confusion Matrices\n# ==========================\nfor model_name in model_labels:\n    print(f\"\\nConfusion Matrix for {model_name}:\")\n    cm = results[model_name]['Confusion Matrix']\n    print(cm)\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f\"Confusion Matrix: {model_name}\")\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}